{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 64, 64, 3)\n",
      "(1080,)\n",
      "test_x shape is (120, 64, 64, 3) test_y shape is (120,)\n",
      "train_x shape is (12288, 1080) test_x shape is (12288, 120)\n"
     ]
    }
   ],
   "source": [
    "train=h5py.File('train_signs.h5','r')\n",
    "train_orig_x=np.array(train['train_set_x'])\n",
    "train_orig_y=np.array(train['train_set_y'])\n",
    "print(train_orig_x.shape)\n",
    "print(train_orig_y.shape)\n",
    "test=h5py.File('test_signs.h5','r')\n",
    "list(test.keys())\n",
    "test_orig_x=np.array(test['test_set_x'])\n",
    "test_orig_y=np.array(test['test_set_y'])\n",
    "print('test_x shape is {} test_y shape is {}'.format(test_orig_x.shape,test_orig_y.shape))\n",
    "#reshaping the data in the form of (nx,m) where m in number of examples\n",
    "train_x_flat=train_orig_x.reshape(train_orig_x.shape[0],-1).T\n",
    "test_x_flat=test_orig_x.reshape(test_orig_x.shape[0],-1).T\n",
    "train_y=train_orig_y\n",
    "test_y=test_orig_y\n",
    "#reshaping the data \n",
    "train_x=train_x_flat/255.\n",
    "test_x=test_x_flat/255.\n",
    "print('train_x shape is {} test_x shape is {}'.format(train_x.shape,test_x.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now choosing the train and test set for only 2 classes 2 class is taken as 1 and rest are 1,3,4 is taken as 0\n",
    "train_cl_df=pd.DataFrame(train_orig_y,columns=['Class_labels'])\n",
    "li_2_train=train_cl_df[train_cl_df.Class_labels==2].index.tolist()\n",
    "train_orig_x_2=train_orig_x[li_2_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_1_3_4_train=train_cl_df[train_cl_df.Class_labels.isin([1,3,4])].index.tolist()\n",
    "train_orig_x_1_3_4=train_orig_x[li_1_3_4_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig_2_1_3_4=np.concatenate((train_orig_x_2,train_orig_x_1_3_4),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing random shuffling before flattening\n",
    "np.random.seed(3)\n",
    "shuffle=np.random.randint(0,720,size=720)\n",
    "train_orig_2_1_3_4=train_orig_2_1_3_4[shuffle]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[233, 227, 227, ..., 226, 236, 229],\n",
       "       [227, 216, 218, ..., 218, 229, 221],\n",
       "       [218, 204, 211, ..., 208, 220, 212],\n",
       "       ..., \n",
       "       [200, 189, 193, ..., 204,  97, 142],\n",
       "       [197, 182, 189, ..., 202,  84,  94],\n",
       "       [187, 175, 181, ..., 201,  71,  60]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_orig_x_2=train_orig_2_1_3_4.reshape(train_orig_2_1_3_4.shape[0],-1).T\n",
    "train_orig_x_2#this is the train data with 2 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_2_1_3_4=np.concatenate((np.ones(180),np.zeros(540)))\n",
    "train_orig_y_2=train_y_2_1_3_4[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2=train_orig_x_2/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#similarly preparing the test data \n",
    "test_cl_df=pd.DataFrame(test_orig_y,columns=['class_labels'])\n",
    "li_test_2=test_cl_df[test_cl_df.class_labels==2].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_test_1_3_4=test_cl_df[test_cl_df.class_labels.isin([1,3,4])].index.tolist()\n",
    "test_orig_x_2=np.concatenate((test_orig_x[li_test_2],test_orig_x[li_test_1_3_4]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig_y_2=np.concatenate((np.ones(20),np.zeros(60)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24,  3, 56, 72,  0, 21, 19, 74, 41, 10, 21, 38, 20, 44, 39, 14, 26,\n",
       "       22, 66,  2, 63, 60,  1, 51, 69, 29, 24, 62,  7, 43, 33, 79, 48, 37,\n",
       "       20, 49, 21, 78, 28, 54,  0, 64, 18, 63, 37, 56, 56, 71, 37, 46, 33,\n",
       "        1, 74, 16, 32, 16, 18, 75, 55, 13, 37, 30, 48, 61, 33, 52,  2, 28,\n",
       "       36, 44, 48, 59, 74, 54, 21, 56, 39, 29, 32, 48])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "test_shuffle=np.random.randint(0,80,80)\n",
    "test_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_orig_x_2=test_orig_x_2[test_shuffle]\n",
    "test_orig_y_2=test_orig_y_2[test_shuffle]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_2=test_orig_x_2.reshape(test_orig_x_2.shape[0],-1).T\n",
    "test_x_2=test_x_2/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig_y_2=test_orig_y_2.reshape(test_orig_y_2.shape[0],-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 720)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_orig_y_2=train_orig_y_2.reshape(train_orig_y_2.shape[0],-1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for mnist dataset\n",
    "import numpy as np\n",
    "import h5py\n",
    "    \n",
    "    \n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x_flatten =train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T #each column is one image\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x.shape\n",
    "test_set_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_y.shape\n",
    "train_set_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    x= 1/(1+np.exp(-z))\n",
    "    return x\n",
    "def initialize_parameters(dim):\n",
    "    w=np.zeros([dim,1])\n",
    "    b=0\n",
    "    return w,b\n",
    "def propagate(w,b,X,Y):\n",
    "    m=X.shape[1]\n",
    "    A=sigmoid(np.dot(w.T,X)+b)\n",
    "    cost = -(np.add(np.sum(np.dot(Y,np.log(A.T))),np.sum(np.dot(1-Y,np.log(1-(A.T)))))/X.shape[1])\n",
    "    #backward propogation\n",
    "    dw = np.dot(X,(A-Y).T)/m\n",
    "    db = np.sum(A-Y)/m\n",
    "    grads={'dw':dw,'db':db}\n",
    "    cost=np.squeeze(cost)\n",
    "#     print('cost squeeze is {} and grads is {}'.format(np.squeeze(cost),grads))\n",
    "    return grads,cost\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    costs=[]\n",
    "    for i in range(num_iterations):\n",
    "        grads,cost=propagate(w,b,X,Y)\n",
    "        dw=grads['dw']\n",
    "        db=grads['db']\n",
    "        w=w-learning_rate*(dw)\n",
    "        b=b-learning_rate*(db)\n",
    "        \n",
    "        \n",
    "        if((i%100)==0):\n",
    "            print('appending costs')\n",
    "            costs.append(cost)\n",
    "        if ((print_cost) and i%100==0):\n",
    "            print('cost at {}th iteration is {}'.format(i,cost))\n",
    "            \n",
    "    w_b_on_completion={'w':w,'b':b}\n",
    "    grads_on_completion={'dw':dw,'db':db}\n",
    "    return w_b_on_completion,grads_on_completion,costs\n",
    "def predict(w,b,X):\n",
    "    m=X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    A=sigmoid(np.dot(w.T,X)+b)\n",
    "    for i in range(A.shape[1]):\n",
    "        if(A[0,i]<0.5):\n",
    "            Y_prediction[0,i]=0\n",
    "        else:\n",
    "            Y_prediction[0,i]=1\n",
    "    return Y_prediction       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined_model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = True):\n",
    "    w,b=initialize_parameters(X_train.shape[0])\n",
    "    print(w.shape,b)\n",
    "    w_complete,grad_complete,costs=optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost=True)\n",
    "    w=w_complete['w']\n",
    "    b=w_complete['b']\n",
    "    predict_train=predict(w,b,X_train)\n",
    "    predict_test=predict(w,b,X_test)\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(predict_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(predict_test - Y_test)) * 100))\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 1) 0\n",
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 2.549628\n",
      "Cost after iteration 200: 0.440687\n",
      "Cost after iteration 300: 1.720467\n",
      "Cost after iteration 400: 0.687398\n",
      "Cost after iteration 500: 1.850746\n",
      "Cost after iteration 600: 1.648013\n",
      "Cost after iteration 700: 1.464200\n",
      "Cost after iteration 800: 0.469830\n",
      "Cost after iteration 900: 0.222382\n",
      "Cost after iteration 1000: 0.298903\n",
      "Cost after iteration 1100: 0.412684\n",
      "Cost after iteration 1200: 0.536552\n",
      "Cost after iteration 1300: 0.668433\n",
      "Cost after iteration 1400: 0.615742\n",
      "Cost after iteration 1500: 0.561227\n",
      "Cost after iteration 1600: 0.511884\n",
      "Cost after iteration 1700: 0.466510\n",
      "Cost after iteration 1800: 0.424236\n",
      "Cost after iteration 1900: 0.384462\n",
      "(12288, 1)\n",
      "(12288, 1)\n",
      "train accuracy: 84.30555555555556 %\n",
      "test accuracy: 78.75 %\n"
     ]
    }
   ],
   "source": [
    "costs=combined_model(train_x_2, train_orig_y_2, test_x_2, test_orig_y_2, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
